From 18f7b319b6d7d29e2d994ebe12951eb75d24c0fc Mon Sep 17 00:00:00 2001
From: SeongJae Park <sj@kernel.org>
Date: Mon, 6 May 2024 16:30:36 -0700
Subject: [PATCH] mm/damon/acma: rename LRU_SORT to ACMA, regardless of case

Signed-off-by: SeongJae Park <sj@kernel.org>
---
 mm/damon/acma.c | 142 +++++++++++++++++++++++++-----------------------
 1 file changed, 74 insertions(+), 68 deletions(-)

diff --git a/mm/damon/acma.c b/mm/damon/acma.c
index 3de2916a65c3..3ed2a350e7f1 100644
--- a/mm/damon/acma.c
+++ b/mm/damon/acma.c
@@ -1,11 +1,17 @@
 // SPDX-License-Identifier: GPL-2.0
 /*
- * DAMON-based LRU-lists Sorting
+ * DAMON-based Access/Contiguity-aware Memory Auto-scaling
+ *
+ * Let user specifies min/max memory of the system and acceptable level of
+ * memory pressure stall level.  While respecting those, automatically scale
+ * the memory of the system up and down by preempting memory from the system
+ * and report it to the host when the system is having memory pressure level
+ * under the threshold, and vice versa, respectively.
  *
  * Author: SeongJae Park <sj@kernel.org>
  */
 
-#define pr_fmt(fmt) "damon-lru-sort: " fmt
+#define pr_fmt(fmt) "damon-acma: " fmt
 
 #include <linux/damon.h>
 #include <linux/kstrtox.h>
@@ -16,27 +22,27 @@
 #ifdef MODULE_PARAM_PREFIX
 #undef MODULE_PARAM_PREFIX
 #endif
-#define MODULE_PARAM_PREFIX "damon_lru_sort."
+#define MODULE_PARAM_PREFIX "damon_acma."
 
 /*
- * Enable or disable DAMON_LRU_SORT.
+ * Enable or disable DAMON_ACMA.
  *
- * You can enable DAMON_LRU_SORT by setting the value of this parameter as
- * ``Y``.  Setting it as ``N`` disables DAMON_LRU_SORT.  Note that
- * DAMON_LRU_SORT could do no real monitoring and LRU-lists sorting due to the
- * watermarks-based activation condition.  Refer to below descriptions for the
- * watermarks parameter for this.
+ * You can enable DAMON_ACMA by setting the value of this parameter as ``Y``.
+ * Setting it as ``N`` disables DAMON_ACMA.  Note that DAMON_ACMA could do no
+ * real monitoring and memory auto-scaling due to the watermarks-based
+ * activation condition.  Refer to below descriptions for the watermarks
+ * parameter for this.
  */
 static bool enabled __read_mostly;
 
 /*
- * Make DAMON_LRU_SORT reads the input parameters again, except ``enabled``.
+ * Make DAMON_ACMA reads the input parameters again, except ``enabled``.
  *
- * Input parameters that updated while DAMON_LRU_SORT is running are not
- * applied by default.  Once this parameter is set as ``Y``, DAMON_LRU_SORT
+ * Input parameters that updated while DAMON_ACMA is running are not
+ * applied by default.  Once this parameter is set as ``Y``, DAMON_ACMA
  * reads values of parametrs except ``enabled`` again.  Once the re-reading is
  * done, this parameter is set as ``N``.  If invalid parameters are found while
- * the re-reading, DAMON_LRU_SORT will be disabled.
+ * the re-reading, DAMON_ACMA will be disabled.
  */
 static bool commit_inputs __read_mostly;
 module_param(commit_inputs, bool, 0600);
@@ -45,7 +51,7 @@ module_param(commit_inputs, bool, 0600);
  * Access frequency threshold for hot memory regions identification in permil.
  *
  * If a memory region is accessed in frequency of this or higher,
- * DAMON_LRU_SORT identifies the region as hot, and mark it as accessed on the
+ * DAMON_ACMA identifies the region as hot, and mark it as accessed on the
  * LRU list, so that it could not be reclaimed under memory pressure.  50% by
  * default.
  */
@@ -55,7 +61,7 @@ module_param(hot_thres_access_freq, ulong, 0600);
 /*
  * Time threshold for cold memory regions identification in microseconds.
  *
- * If a memory region is not accessed for this or longer time, DAMON_LRU_SORT
+ * If a memory region is not accessed for this or longer time, DAMON_ACMA
  * identifies the region as cold, and mark it as unaccessed on the LRU list, so
  * that it could be reclaimed first under memory pressure.  120 seconds by
  * default.
@@ -63,7 +69,7 @@ module_param(hot_thres_access_freq, ulong, 0600);
 static unsigned long cold_min_age __read_mostly = 120000000;
 module_param(cold_min_age, ulong, 0600);
 
-static struct damos_quota damon_lru_sort_quota = {
+static struct damos_quota damon_acma_quota = {
 	/* Use up to 10 ms per 1 sec, by default */
 	.ms = 10,
 	.sz = 0,
@@ -73,30 +79,30 @@ static struct damos_quota damon_lru_sort_quota = {
 	.weight_nr_accesses = 1,
 	.weight_age = 0,
 };
-DEFINE_DAMON_MODULES_DAMOS_TIME_QUOTA(damon_lru_sort_quota);
+DEFINE_DAMON_MODULES_DAMOS_TIME_QUOTA(damon_acma_quota);
 
-static struct damos_watermarks damon_lru_sort_wmarks = {
+static struct damos_watermarks damon_acma_wmarks = {
 	.metric = DAMOS_WMARK_FREE_MEM_RATE,
 	.interval = 5000000,	/* 5 seconds */
 	.high = 200,		/* 20 percent */
 	.mid = 150,		/* 15 percent */
 	.low = 50,		/* 5 percent */
 };
-DEFINE_DAMON_MODULES_WMARKS_PARAMS(damon_lru_sort_wmarks);
+DEFINE_DAMON_MODULES_WMARKS_PARAMS(damon_acma_wmarks);
 
-static struct damon_attrs damon_lru_sort_mon_attrs = {
+static struct damon_attrs damon_acma_mon_attrs = {
 	.sample_interval = 5000,	/* 5 ms */
 	.aggr_interval = 100000,	/* 100 ms */
 	.ops_update_interval = 0,
 	.min_nr_regions = 10,
 	.max_nr_regions = 1000,
 };
-DEFINE_DAMON_MODULES_MON_ATTRS_PARAMS(damon_lru_sort_mon_attrs);
+DEFINE_DAMON_MODULES_MON_ATTRS_PARAMS(damon_acma_mon_attrs);
 
 /*
  * Start of the target memory region in physical address.
  *
- * The start physical address of memory region that DAMON_LRU_SORT will do work
+ * The start physical address of memory region that DAMON_ACMA will do work
  * against.  By default, biggest System RAM is used as the region.
  */
 static unsigned long monitor_region_start __read_mostly;
@@ -105,7 +111,7 @@ module_param(monitor_region_start, ulong, 0600);
 /*
  * End of the target memory region in physical address.
  *
- * The end physical address of memory region that DAMON_LRU_SORT will do work
+ * The end physical address of memory region that DAMON_ACMA will do work
  * against.  By default, biggest System RAM is used as the region.
  */
 static unsigned long monitor_region_end __read_mostly;
@@ -114,23 +120,23 @@ module_param(monitor_region_end, ulong, 0600);
 /*
  * PID of the DAMON thread
  *
- * If DAMON_LRU_SORT is enabled, this becomes the PID of the worker thread.
+ * If DAMON_ACMA is enabled, this becomes the PID of the worker thread.
  * Else, -1.
  */
 static int kdamond_pid __read_mostly = -1;
 module_param(kdamond_pid, int, 0400);
 
-static struct damos_stat damon_lru_sort_hot_stat;
-DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_lru_sort_hot_stat,
-		lru_sort_tried_hot_regions, lru_sorted_hot_regions,
+static struct damos_stat damon_acma_hot_stat;
+DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_acma_hot_stat,
+		acma_tried_hot_regions, acmaed_hot_regions,
 		hot_quota_exceeds);
 
-static struct damos_stat damon_lru_sort_cold_stat;
-DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_lru_sort_cold_stat,
-		lru_sort_tried_cold_regions, lru_sorted_cold_regions,
+static struct damos_stat damon_acma_cold_stat;
+DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_acma_cold_stat,
+		acma_tried_cold_regions, acmaed_cold_regions,
 		cold_quota_exceeds);
 
-static struct damos_access_pattern damon_lru_sort_stub_pattern = {
+static struct damos_access_pattern damon_acma_stub_pattern = {
 	/* Find regions having PAGE_SIZE or larger size */
 	.min_sz_region = PAGE_SIZE,
 	.max_sz_region = ULONG_MAX,
@@ -145,10 +151,10 @@ static struct damos_access_pattern damon_lru_sort_stub_pattern = {
 static struct damon_ctx *ctx;
 static struct damon_target *target;
 
-static struct damos *damon_lru_sort_new_scheme(
+static struct damos *damon_acma_new_scheme(
 		struct damos_access_pattern *pattern, enum damos_action action)
 {
-	struct damos_quota quota = damon_lru_sort_quota;
+	struct damos_quota quota = damon_acma_quota;
 
 	/* Use half of total quota for hot/cold pages sorting */
 	quota.ms = quota.ms / 2;
@@ -163,29 +169,29 @@ static struct damos *damon_lru_sort_new_scheme(
 			/* under the quota. */
 			&quota,
 			/* (De)activate this according to the watermarks. */
-			&damon_lru_sort_wmarks);
+			&damon_acma_wmarks);
 }
 
 /* Create a DAMON-based operation scheme for hot memory regions */
-static struct damos *damon_lru_sort_new_hot_scheme(unsigned int hot_thres)
+static struct damos *damon_acma_new_hot_scheme(unsigned int hot_thres)
 {
-	struct damos_access_pattern pattern = damon_lru_sort_stub_pattern;
+	struct damos_access_pattern pattern = damon_acma_stub_pattern;
 
 	pattern.min_nr_accesses = hot_thres;
-	return damon_lru_sort_new_scheme(&pattern, DAMOS_LRU_PRIO);
+	return damon_acma_new_scheme(&pattern, DAMOS_LRU_PRIO);
 }
 
 /* Create a DAMON-based operation scheme for cold memory regions */
-static struct damos *damon_lru_sort_new_cold_scheme(unsigned int cold_thres)
+static struct damos *damon_acma_new_cold_scheme(unsigned int cold_thres)
 {
-	struct damos_access_pattern pattern = damon_lru_sort_stub_pattern;
+	struct damos_access_pattern pattern = damon_acma_stub_pattern;
 
 	pattern.max_nr_accesses = 0;
 	pattern.min_age_region = cold_thres;
-	return damon_lru_sort_new_scheme(&pattern, DAMOS_LRU_DEPRIO);
+	return damon_acma_new_scheme(&pattern, DAMOS_LRU_DEPRIO);
 }
 
-static void damon_lru_sort_copy_quota_status(struct damos_quota *dst,
+static void damon_acma_copy_quota_status(struct damos_quota *dst,
 		struct damos_quota *src)
 {
 	dst->total_charged_sz = src->total_charged_sz;
@@ -196,14 +202,14 @@ static void damon_lru_sort_copy_quota_status(struct damos_quota *dst,
 	dst->charge_addr_from = src->charge_addr_from;
 }
 
-static int damon_lru_sort_apply_parameters(void)
+static int damon_acma_apply_parameters(void)
 {
 	struct damos *scheme, *hot_scheme, *cold_scheme;
 	struct damos *old_hot_scheme = NULL, *old_cold_scheme = NULL;
 	unsigned int hot_thres, cold_thres;
 	int err = 0;
 
-	err = damon_set_attrs(ctx, &damon_lru_sort_mon_attrs);
+	err = damon_set_attrs(ctx, &damon_acma_mon_attrs);
 	if (err)
 		return err;
 
@@ -215,23 +221,23 @@ static int damon_lru_sort_apply_parameters(void)
 		old_cold_scheme = scheme;
 	}
 
-	hot_thres = damon_max_nr_accesses(&damon_lru_sort_mon_attrs) *
+	hot_thres = damon_max_nr_accesses(&damon_acma_mon_attrs) *
 		hot_thres_access_freq / 1000;
-	hot_scheme = damon_lru_sort_new_hot_scheme(hot_thres);
+	hot_scheme = damon_acma_new_hot_scheme(hot_thres);
 	if (!hot_scheme)
 		return -ENOMEM;
 	if (old_hot_scheme)
-		damon_lru_sort_copy_quota_status(&hot_scheme->quota,
+		damon_acma_copy_quota_status(&hot_scheme->quota,
 				&old_hot_scheme->quota);
 
-	cold_thres = cold_min_age / damon_lru_sort_mon_attrs.aggr_interval;
-	cold_scheme = damon_lru_sort_new_cold_scheme(cold_thres);
+	cold_thres = cold_min_age / damon_acma_mon_attrs.aggr_interval;
+	cold_scheme = damon_acma_new_cold_scheme(cold_thres);
 	if (!cold_scheme) {
 		damon_destroy_scheme(hot_scheme);
 		return -ENOMEM;
 	}
 	if (old_cold_scheme)
-		damon_lru_sort_copy_quota_status(&cold_scheme->quota,
+		damon_acma_copy_quota_status(&cold_scheme->quota,
 				&old_cold_scheme->quota);
 
 	damon_set_schemes(ctx, &hot_scheme, 1);
@@ -242,7 +248,7 @@ static int damon_lru_sort_apply_parameters(void)
 					&monitor_region_end);
 }
 
-static int damon_lru_sort_turn(bool on)
+static int damon_acma_turn(bool on)
 {
 	int err;
 
@@ -253,7 +259,7 @@ static int damon_lru_sort_turn(bool on)
 		return err;
 	}
 
-	err = damon_lru_sort_apply_parameters();
+	err = damon_acma_apply_parameters();
 	if (err)
 		return err;
 
@@ -264,7 +270,7 @@ static int damon_lru_sort_turn(bool on)
 	return 0;
 }
 
-static int damon_lru_sort_enabled_store(const char *val,
+static int damon_acma_enabled_store(const char *val,
 		const struct kernel_param *kp)
 {
 	bool is_enabled = enabled;
@@ -282,7 +288,7 @@ static int damon_lru_sort_enabled_store(const char *val,
 	if (!ctx)
 		goto set_param_out;
 
-	err = damon_lru_sort_turn(enable);
+	err = damon_acma_turn(enable);
 	if (err)
 		return err;
 
@@ -292,61 +298,61 @@ static int damon_lru_sort_enabled_store(const char *val,
 }
 
 static const struct kernel_param_ops enabled_param_ops = {
-	.set = damon_lru_sort_enabled_store,
+	.set = damon_acma_enabled_store,
 	.get = param_get_bool,
 };
 
 module_param_cb(enabled, &enabled_param_ops, &enabled, 0600);
 MODULE_PARM_DESC(enabled,
-	"Enable or disable DAMON_LRU_SORT (default: disabled)");
+	"Enable or disable DAMON_ACMA (default: disabled)");
 
-static int damon_lru_sort_handle_commit_inputs(void)
+static int damon_acma_handle_commit_inputs(void)
 {
 	int err;
 
 	if (!commit_inputs)
 		return 0;
 
-	err = damon_lru_sort_apply_parameters();
+	err = damon_acma_apply_parameters();
 	commit_inputs = false;
 	return err;
 }
 
-static int damon_lru_sort_after_aggregation(struct damon_ctx *c)
+static int damon_acma_after_aggregation(struct damon_ctx *c)
 {
 	struct damos *s;
 
 	/* update the stats parameter */
 	damon_for_each_scheme(s, c) {
 		if (s->action == DAMOS_LRU_PRIO)
-			damon_lru_sort_hot_stat = s->stat;
+			damon_acma_hot_stat = s->stat;
 		else if (s->action == DAMOS_LRU_DEPRIO)
-			damon_lru_sort_cold_stat = s->stat;
+			damon_acma_cold_stat = s->stat;
 	}
 
-	return damon_lru_sort_handle_commit_inputs();
+	return damon_acma_handle_commit_inputs();
 }
 
-static int damon_lru_sort_after_wmarks_check(struct damon_ctx *c)
+static int damon_acma_after_wmarks_check(struct damon_ctx *c)
 {
-	return damon_lru_sort_handle_commit_inputs();
+	return damon_acma_handle_commit_inputs();
 }
 
-static int __init damon_lru_sort_init(void)
+static int __init damon_acma_init(void)
 {
 	int err = damon_modules_new_paddr_ctx_target(&ctx, &target);
 
 	if (err)
 		return err;
 
-	ctx->callback.after_wmarks_check = damon_lru_sort_after_wmarks_check;
-	ctx->callback.after_aggregation = damon_lru_sort_after_aggregation;
+	ctx->callback.after_wmarks_check = damon_acma_after_wmarks_check;
+	ctx->callback.after_aggregation = damon_acma_after_aggregation;
 
 	/* 'enabled' has set before this function, probably via command line */
 	if (enabled)
-		err = damon_lru_sort_turn(true);
+		err = damon_acma_turn(true);
 
 	return err;
 }
 
-module_init(damon_lru_sort_init);
+module_init(damon_acma_init);
-- 
2.39.2

