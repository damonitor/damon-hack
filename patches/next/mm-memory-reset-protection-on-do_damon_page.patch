From: SeongJae Park <sj@kernel.org>
Date: Sat, 26 Jul 2025 14:17:39 -0700
Subject: [PATCH] mm/memory: reset protection on do_damon_page()

Signed-off-by: SeongJae Park <sj@kernel.org>
---
 mm/memory.c | 26 ++++++++++++++++++++++++++
 1 file changed, 26 insertions(+)

diff --git a/mm/memory.c b/mm/memory.c
index bf7e256b1f40..656e610867b0 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -5979,11 +5979,37 @@ static vm_fault_t do_damon_page(struct vm_fault *vmf, bool huge_pmd)
 		.addr = vmf->address,
 		.size = 1,
 	};
+	struct vm_area_struct *vma = vmf->vma;
+	struct folio *folio;
+	pte_t pte, old_pte;
+	bool writable = false, ignore_writable = false;
+	bool pte_write_upgrade = vma_wants_manual_pte_write_upgrade(vma);
 
 	if (huge_pmd)
 		access_report.addr = PFN_PHYS(pmd_pfn(vmf->orig_pmd));
 	else
 		access_report.addr = PFN_PHYS(pte_pfn(vmf->orig_pte));
+
+	spin_lock(vmf->ptl);
+	old_pte = ptep_get(vmf->pte);
+	if (unlikely(!pte_same(old_pte, vmf->orig_pte))) {
+		pte_unmap_unlock(vmf->pte, vmf->ptl);
+		return 0;
+	}
+	pte = pte_modify(old_pte, vma->vm_page_prot);
+	writable = pte_write(pte);
+	if (!writable && pte_write_upgrade &&
+			can_change_pte_writable(vma, vmf->address, pte))
+		writable = true;
+	folio = vm_normal_folio(vma, vmf->address, pte);
+	if (folio && folio_test_large(folio))
+		numa_rebuild_large_mapping(vmf, vma, folio, pte,
+				ignore_writable, pte_write_upgrade);
+	else
+		numa_rebuild_single_mapping(vmf, vma, vmf->address, vmf->pte,
+				writable);
+	pte_unmap_unlock(vmf->pte, vmf->ptl);
+
 	damon_report_access(&access_report);
 	return 0;
 }
-- 
2.39.5

